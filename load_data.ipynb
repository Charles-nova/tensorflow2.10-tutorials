{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180a917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fb58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\WINDOWS\\\\Temp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# os.environ['XLA_FLAGS']\n",
    "# os.environ是一个字典，可以通过get方法获得对应的值\n",
    "os.environ['SYSTEMROOT']\n",
    "os.environ['TEMP']\n",
    "# 设置系统环境变量\n",
    "# os.putenv('环境变量名称','环境变量值') \n",
    "# 修改环境变量\n",
    "# os.environ['环境变量名称']='新环境变量名称'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e450df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acb60b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435 , 0.335 , 0.11  , ..., 0.1355, 0.0775, 0.0965],\n",
       "       [0.585 , 0.45  , 0.125 , ..., 0.3545, 0.2075, 0.225 ],\n",
       "       [0.655 , 0.51  , 0.16  , ..., 0.396 , 0.2825, 0.37  ],\n",
       "       ...,\n",
       "       [0.53  , 0.42  , 0.13  , ..., 0.3745, 0.167 , 0.249 ],\n",
       "       [0.395 , 0.315 , 0.105 , ..., 0.1185, 0.091 , 0.1195],\n",
       "       [0.45  , 0.355 , 0.12  , ..., 0.1145, 0.0665, 0.16  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features =abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop(\"Age\")\n",
    "abalone_features = np.array(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()\n",
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([layers.Dense(64), layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d2066",
   "metadata": {},
   "source": [
    "## Mixed data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64087b08",
   "metadata": {},
   "source": [
    "Download Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e0d9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cf5f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = titanic.copy()\n",
    "titanic_Y = titanic_X.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cfdd7",
   "metadata": {},
   "source": [
    "The Keras preprocessing layers are parts of the model. Keras functional API operates on 'symbolic' tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9f1dd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# create a symbolic input\n",
    "# input = tf.keras.Input(shape=(784,), dtype=tf.float32)  # TensorShape([None, 784])\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "result = 2 * input + 1\n",
    "img_input = tf.keras.Input(shape=(32, 32, 3)) # 这个图像的维度顺序和torch不一样\n",
    "calc = tf.keras.Model(inputs=input, outputs=result)\n",
    "print(calc(1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a6e05",
   "metadata": {},
   "source": [
    "## Match the names and data-types of the CSV columns\n",
    "build a set of symbolic tf.keras.Input objects, matching the names and data-types of the CSV columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9625de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, col in titanic_X.items():\n",
    "    dtype = col.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcacd84",
   "metadata": {},
   "source": [
    "## Concatenate the numeric inputs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cebaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'normalization_4')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_X = {name:input for name,input in inputs.items()\n",
    "            if input.dtype==tf.float32}\n",
    "x = layers.Concatenate()(list(numeric_X.values()))\n",
    "norm = layers.Normalization()\n",
    "# 在对数据进行处理前，需要调用adapt，对数据进行学习，adapt必须在调用fit，evaluate，predict之前\n",
    "norm.adapt(np.array(titanic[numeric_X.keys()])) # 调用实际的数据\n",
    "all_numeric_inputs = norm(x) # 抽象的预处理层\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b2233",
   "metadata": {},
   "source": [
    "## Build preprocessing model\n",
    "For the string inputs use the `tf.keras.layers.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `tf.keras.layers.CategoryEncoding` to convert the indexes into float32 data appropriate for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1813c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype==tf.float32:\n",
    "        continue\n",
    "    # 指定vocabulary后可以不用使用adapt()\n",
    "    lookup = layers.StringLookup(vocabulary=np.unique(titanic_X[name]), output_mode='one_hot')\n",
    "#     emb = layers.Embedding(input_dim=lookup.vocabulary_size(), output_dim=32)\n",
    "    \n",
    "    x = lookup(input)\n",
    "#     x = emb(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5290f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# 拼接到一起\n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "# 建立model\n",
    "titanic_preprocessing_model = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing_model , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172c279",
   "metadata": {},
   "source": [
    "## Convert pandas DataFrame to Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "582aaa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value)\n",
    "                        for name, value in titanic_X.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb1cf181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 28), dtype=float32, numpy=\n",
       "array([[-0.610415 ,  0.395198 , -0.4790527, -0.4974028,  0.       ,\n",
       "         0.       ,  1.       ,  0.       ,  0.       ,  0.       ,\n",
       "         1.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  1.       ,\n",
       "         0.       ,  0.       ,  0.       ,  1.       ,  0.       ,\n",
       "         0.       ,  1.       ,  0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing_model(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375156c5",
   "metadata": {},
   "source": [
    "## Build the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79e519ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_model, inputs):\n",
    "    \"\"\"\n",
    "    :param preprocessing_model: 定义好的预处理模型 \n",
    "    :param inputs: 输入层，tf.keras.Input的集合\n",
    "    \"\"\"\n",
    "    body = tf.keras.Sequential([\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    preprocessed_inputs = preprocessing_model(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    # 通过inputs和result建立model\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model\n",
    "titanic_model = titanic_model(titanic_preprocessing_model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "366728d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 4s 9ms/step - loss: 0.7506\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6095\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5349\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4936\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4682\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4502\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4391\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4322\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4270\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4244\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4219\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4216\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4199\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4237\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4207\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4195\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4205\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4193\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4183\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4185\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4191\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4187\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4190\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4193\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4197\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4184\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4174\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4185\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4172\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4179\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4177\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4184\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4185\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4172\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4178\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4178\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4168\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4185\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4175\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4187\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4195\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4180\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4179\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4197\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4172\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4203\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4182\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4181\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4183\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fb6edb9d00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意输入为\n",
    "titanic_model.fit(x=titanic_features_dict, y=titanic_Y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1afe0368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbbf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
